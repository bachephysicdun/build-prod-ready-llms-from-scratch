{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924e31bb",
   "metadata": {},
   "source": [
    "# Position-wise Feed Forward layer in Attention is All You Need (AAYN)\n",
    "\n",
    "### Ref: [The AiEdge Newsletter](https://drive.google.com/file/d/1Je2SAFBlsWcgwzK_gl1_f-LtPK3SOzg3/view)\n",
    "\n",
    "<img src=\"../../assets/poswise_feedforward.png\" width=\"700\" height=\"200\">\n",
    "\n",
    "Position-wise feed forward network will be used in the Encoder Block as well as Decoder Block. (Encoder block contains two main sub-layers: 1. Multi-head self-attention and 2. position-wise feed forward network while Decoder block contains of three main sub-layers: 1. Multi-head self-attention, 2. Multi-head cross attention, and 3. position-wise feed forward network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422b72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce46616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementing position-wise feed forward network\n",
    "\n",
    "    Args:\n",
    "        d_model (int): internal dimension of the model or dimension of embeddings.\n",
    "        (also known as 'hidden_size')\n",
    "        d_ff (int): dimension of feed-forward network (usually larger than d_model)\n",
    "    \"\"\"    \n",
    "    def __init__(self, d_model: int, d_ff: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.W1 = nn.Linear(d_model, d_ff)\n",
    "        self.W2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        forward pass of the feed forward network\n",
    "        Args:\n",
    "            x (torch.Tensor): input tensor of shape [batch_size, seq_len, d_model]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output tensor of shape [batch_size, seq_len, d_model]\n",
    "        \"\"\"        \n",
    "        x = self.W1(x)      # [batch_size, seq_len, d_ff]\n",
    "        x = self.relu(x)    # add non-linearity\n",
    "        x = self.W2(x)      # [batch_size, seq_len, d_model]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bebdc3",
   "metadata": {},
   "source": [
    "#### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6378e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x: torch.Size([2, 5, 12]), and feed forward output: torch.Size([2, 5, 12])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "d_model = 12    # or model dim or hidden size\n",
    "seq_len = 5\n",
    "d_ff = 24\n",
    "\n",
    "# generate random dummy input\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# instantiat the network\n",
    "pffn = PositionwiseFeedForward(d_model, d_ff)\n",
    "out = pffn(x) # forward pass\n",
    "\n",
    "print(f'input x: {x.size()}, and feed forward output: {out.size()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
